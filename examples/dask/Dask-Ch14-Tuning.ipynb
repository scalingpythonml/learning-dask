{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "387b8f83-88ae-49f9-9692-43837d7c324d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask_jobqueue import SLURMCluster\n",
    "from dask.distributed import Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4afb695c-ca55-483d-87b7-f206f038070c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "632d98e5-b531-49ba-b093-ceae295f1704",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d7c3ab6-f58e-40ba-9782-a5c883f9c787",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tag::ex_monitor_distributed_threads[]\n",
    "import threading, sys, time\n",
    "\n",
    "main_thread = threading.get_ident()\n",
    "\n",
    "def print_frame(frame, event):\n",
    "    print(frame, event)\n",
    "    return print_frame\n",
    "\n",
    "current_frame = sys._getframe().f_trace = print_frame\n",
    "\n",
    "def print_frame():\n",
    "    frame = sys._current_frames()[main_thread]\n",
    "    print frame\n",
    "    \n",
    "def print_worker_config():\n",
    "    return dask.config.get(\"distributed.worker.use-file-locking\")\n",
    "#end::ex_monitor_distributed_threads[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3720ccc6-e8c0-44c0-8c83-da99870a8c8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87cea694-20db-48e1-a047-caca0ae9eca8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from dask.distributed import Client\n",
    "from dask.distributed import LocalCluster\n",
    "cluster = LocalCluster(n_workers=10) \n",
    "client = Client(cluster)\n",
    "client\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d884e7d-02d7-4410-97f6-3f8796ed3ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.array as da\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd89fdf4-72cf-42b8-bc5b-f12f5aa3f0af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d88ca80a-16a0-4459-89d0-2ce7b4389839",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tag::ex_generate_performance_report[]\n",
    "from dask.distributed import performance_report\n",
    "\n",
    "with performance_report(filename=\"computation_report.html\"):\n",
    "    gnarl = da.random.beta(1,2, size=(10000, 10000, 10), chunks=(1000,1000,5))\n",
    "    x = da.random.random((10000, 10000, 10), chunks=(1000, 1000, 5))\n",
    "    y = (da.arccos(x)*gnarl).sum(axis=(1,2))\n",
    "    y.compute()\n",
    "#end::ex_generate_performance_report[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf7a5c6-a891-4eb1-b2d8-0f638a25144e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tag::ex_get_task_stream[]\n",
    "from dask.distributed import get_task_stream\n",
    "\n",
    "with get_task_stream() as ts:\n",
    "    gnarl = da.random.beta(1,2, size=(100, 100, 10), chunks=(100,100,5))\n",
    "    x = da.random.random((100, 100, 10), chunks=(100, 100, 5))\n",
    "    y = (da.arccos(x)*gnarl).sum(axis=(1,2))\n",
    "    y.compute()\n",
    "history = ts.data\n",
    "\n",
    "#display the task stream data as dataframe\n",
    "history_frame = pd.DataFrame(history, columns = ['worker','status','nbytes', 'thread', 'type', 'typename', 'metadata', 'startstops', 'key'])\n",
    "\n",
    "#plot task stream\n",
    "ts.figure\n",
    "#end::ex_get_task_stream[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54623692-b31e-48b2-8e67-cb1d6901701b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28fdd36d-0d29-4acf-8a82-42f467ef4121",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tag::ex_memory_sampler[]\n",
    "from distributed.diagnostics import MemorySampler\n",
    "from dask_kubernetes import KubeCluster\n",
    "from distributed import Client\n",
    "\n",
    "cluster = KubeCluster()\n",
    "client = Client(cluster)\n",
    "\n",
    "ms = MemorySampler()\n",
    "\n",
    "#some gnarly compute\n",
    "gnarl = da.random.beta(1,2, size=(100, 100, 10), chunks=(100,100,5))\n",
    "x = da.random.random((100, 100, 10), chunks=(100, 100, 5))\n",
    "y = (da.arccos(x)*gnarl).sum(axis=(1,2))\n",
    "    \n",
    "with ms.sample(\"memory without adaptive clusters\"):\n",
    "    y.compute()\n",
    "\n",
    "#enable adaptive scaling\n",
    "cluster.adapt(minimum=0, maximum=100) \n",
    "\n",
    "with ms.sample(\"memory with adaptive clusters\"):\n",
    "    y.compute()\n",
    "\n",
    "#plot the differences\n",
    "ms.plot(align=True, grid=True)\n",
    "\n",
    "#end::ex_memory_sampler[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f5d052c-6132-4109-8833-08d241eae979",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tag::ex_hpc_infinite_workers[]\n",
    "from dask_jobqueue import SLURMCluster\n",
    "from dask import delayed\n",
    "from dask.distributed import Client\n",
    "\n",
    "#we give walltime of 4 hours to the cluster spawn\n",
    "#each Dask workers are told they have 5 min less than that for Dask to manage\n",
    "#we tell workers to stagger their start and close in a random interval of 5min\n",
    "#some workers will die, but others will be staggered alive, avoiding loss of job\n",
    "\n",
    "cluster = SLURMCluster(    \n",
    "    walltime=\"04:00:00\",\n",
    "    cores=24,\n",
    "    processes=6\n",
    "    memory=\"8gb\",\n",
    "    #args passed directly to worker\n",
    "    worker_extra_args=[\"--lifetime\", \"235m\", \"--lifetime-stagger\", \"5m\"],\n",
    "    #path to the interpreter that you want to run the batch submission script\n",
    "    shebang='#!/usr/bin/env zsh',\n",
    "    #path to desired python runtime if you have a separate one\n",
    "    python='~/miniconda/bin/python'\n",
    ")\n",
    "\n",
    "client = Client(cluster)\n",
    "\n",
    "#end::ex_hpc_infinite_workers[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf1356d-6bd6-4987-bb6d-fed8697663f7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#tag::ex_yarn_deployment_tuning[]\n",
    "\n",
    "from dask_yarn import YarnCluster\n",
    "from dask.distributed import Client\n",
    "import logging\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "WORKER_ENV = {\"HADOOP_CONF_DIR\": \"/data/app/spark-yarn/hadoop-conf\", \"JAVA_HOME\": \"/usr/lib/jvm/java\"}\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.DEBUG,\n",
    "    format=\"%(asctime)s %(levelname)s %(name)s: %(message)s\")\n",
    "\n",
    "logger.info(\"Initialising YarnCluster\")\n",
    "cluster_start_time = time.time()\n",
    "\n",
    "# say your desired conda environment for workers are located at\n",
    "# /home/mkimmins/anaconda/bin/python\n",
    "# similar syntax for venv and python executable\n",
    "cluster = YarnCluster(\n",
    "    environment='conda:///home/mkimmins/anaconda/bin/python',\n",
    "    worker_vcores=2,\n",
    "    worker_memory=\"4GiB\")\n",
    "\n",
    "logger.info(\"Initialising YarnCluster: done in %.4f\", time.time() - cluster_start_time)\n",
    "\n",
    "logger.info(\"Initialising Client\")\n",
    "client = Client(cluster)\n",
    "logger.info(\"Initialising Client: done in %.4f\", time.time() - client_start_time)\n",
    "\n",
    "# Important and common misconfig is to not have node's versions match\n",
    "versions = dask_client.get_versions(check=True)\n",
    "\n",
    "#end::ex_yarn_deployment_tuning[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5da099b-2425-43f0-8fdf-c85f782e4132",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tag::ex_yarn_deployment_CLI_tuning[]\n",
    "!dask-yarn submit\n",
    "  --environment home/mkimmins/anaconda/bin/python \\\n",
    "  --worker-count 20 \\\n",
    "  --worker-vcores 2 \\\n",
    "  --worker-memory 4GiB \\\n",
    "  your_python_script.py\n",
    "\n",
    "# Since we already deployed and ran YARN cluster,\n",
    "# we replace YarnCluster(...) with from_current() to reference it\n",
    "cluster = YarnCluster.from_current()\n",
    "    \n",
    "# This would give you YARN application ID\n",
    "# application_1516806604516_0019\n",
    "# status check, kill, view log of application\n",
    "!dask-yarn status application_1516806604516_0019\n",
    "!dask-yarn kill application_1516806604516_0019\n",
    "!yarn logs -applicationId application_1516806604516_0019\n",
    "\n",
    "#end::ex_yarn_deployment_tuning[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa227fc-ff02-47b5-941b-b721cf10c4e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tag::ex_deploy_SLURM_by_hand[]\n",
    "from dask_jobqueue import SLURMCluster\n",
    "from dask.distributed import Client\n",
    "\n",
    "def create_slurm_clusters(cores, processes, workers, memory=\"16GB\", queue='regular', account=\"slurm_account\", username=\"mkimmins\"):\n",
    "    cluster = SLURMCluster(\n",
    "        #ensure walltime request is reasonable within your specific cluster    \n",
    "        walltime=\"04:00:00\",\n",
    "        queue=queue,\n",
    "        account=account,        \n",
    "        cores=cores,\n",
    "        processes=processes,\n",
    "        memory=memory,\n",
    "        worker_extra_args=[\"--resources GPU=1\"],\n",
    "        job_extra=['--gres=gpu:1'],\n",
    "        job_directives_skip=['--mem', 'another-string'],\n",
    "        job_script_prologue = ['/your_path/pre_run_script.sh', 'source venv/bin/activate'],\n",
    "        interface='ib0',\n",
    "        log_directory='dask_slurm_logs',\n",
    "        python=f'srun -n 1 -c {processes} python',\n",
    "        local_directory=f'/dev/{username}',\n",
    "        death_timeout=300\n",
    "    )\n",
    "    cluster.start_workers(workers)\n",
    "    return cluster\n",
    "\n",
    "cluster = create_slurm_clusters(cores=4, processes=1, workers=4)\n",
    "cluster.scale(10)\n",
    "client = Client(cluster)\n",
    "#end::ex_deploy_SLURM_by_hand[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f5d795-4ab4-4712-9adf-921b1574a17c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tag::ex_slurm_deployment_tuning[]\n",
    "import time\n",
    "from dask import delayed\n",
    "from dask.distributed import Client, LocalCluster\n",
    "# Note we introduce progress bar for future execution in a distributed context here\n",
    "from dask.distributed import progress\n",
    "from dask_jobqueue import SLURMCluster\n",
    "import numpy as np\n",
    "import logging\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "logging.basicConfig(\n",
    "    level=logging.DEBUG,\n",
    "    format=\"%(asctime)s %(levelname)s %(name)s: %(message)s\")\n",
    "\n",
    "def visit_url(i):\n",
    "    return \"Some fancy operation happened. Trust me.\"\n",
    "\n",
    "@delayed\n",
    "def crawl(url, depth=0, maxdepth=1, maxlinks=4):\n",
    "    # some complicated and async job\n",
    "    # refer to chapter 2 for full implementation of crawl    \n",
    "    time.sleep(1)\n",
    "    some_output = visit_url(url)\n",
    "    return some_output\n",
    "\n",
    "def main_event(client):\n",
    "    njobs = 100\n",
    "    outputs = []\n",
    "    for i in range(njobs):\n",
    "        # assume we have a queue of work to do\n",
    "        url = work_queue.deque()\n",
    "        output = crawl(url)\n",
    "        outputs.append(output)\n",
    "\n",
    "    results = client.persist(outputs)\n",
    "    logger.info(f\"Running main loop...\")\n",
    "    progress(results)\n",
    "\n",
    "def cli():\n",
    "    cluster = create_slurm_clusters(cores=10, processes=10, workers=2)\n",
    "    logger.info(f\"Submitting SLURM job with jobscript: {cluster.job_script()}\")\n",
    "    client = Client(cluster)\n",
    "    main_event(client)    \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    logger.info(\"Initialising SLURM Cluster\")\n",
    "    cli()\n",
    "#end::ex_slurm_deployment_tuning[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a88ed8e-ed3f-4ef7-885c-2cbed94f6861",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37795116-8c26-4a74-bbe7-39a2a38b5980",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be112ca-ecba-459c-8d23-45d350ad127c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "client.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:mika-dask]",
   "language": "python",
   "name": "conda-env-mika-dask-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
